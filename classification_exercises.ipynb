{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd73d7d",
   "metadata": {},
   "source": [
    "### Data Acquisition Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b830b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from env import get_db_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f15d40",
   "metadata": {},
   "source": [
    "4. In a jupyter notebook, `classification_exercises.ipynb`, use a python module (pydata or seaborn datasets) containing datasets as a source from the iris data. Create a pandas dataframe, `df_iris`, from this data.\n",
    "\n",
    "    - print the first 3 rows\n",
    "    - print the number of rows and columns (shape)\n",
    "    - print the column names\n",
    "    - print the data type of each column\n",
    "    - print the summary statistics for each of the numeric variables. Would you\n",
    "      recommend rescaling the data based on these statistics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ac3e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_iris = data('iris')\n",
    "df_iris.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2681aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2161a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_iris.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5ec094",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b8cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1f5980",
   "metadata": {},
   "source": [
    "5. Read the data from [this google sheet](https://docs.google.com/spreadsheets/d/1Uhtml8KY19LILuZsrDtlsHHDC9wuDGUSe8LTEwvdI5g/edit?usp=sharing) into a dataframe, `df_google`\n",
    "\n",
    "    - print the first 3 rows\n",
    "    - print the number of rows and columns\n",
    "    - print the column names\n",
    "    - print the data type of each column\n",
    "    - print the summary statistics for each of the numeric variables\n",
    "    - print the unique values for each of your categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_url = \\\n",
    "'https://docs.google.com/spreadsheets/d/1Uhtml8KY19LILuZsrDtlsHHDC9wuDGUSe8LTEwvdI5g/edit#gid=341089357'\n",
    "sheet_url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "df_google = pd.read_csv(sheet_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1afc465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0000469",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_google.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c2d700",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_google.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cfb771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the unique values for each of your categorical variables\n",
    "list(df_google.Name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed09830",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_google.Sex.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d79838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google.Ticket.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df04be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google.Cabin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_google.Embarked.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7007eff7",
   "metadata": {},
   "source": [
    "6. Download the previous exercise's file into an excel (File → Download → Microsoft Excel). Read the downloaded file into a dataframe named ```df_excel```.\n",
    "\n",
    "    - assign the first 100 rows to a new dataframe, `df_excel_sample`\n",
    "    - print the number of rows of your original dataframe\n",
    "    - print the first 5 column names\n",
    "    - print the column names that have a data type of `object`\n",
    "    - compute the range for each of the numeric variables.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80473d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel('train.xlsx')\n",
    "df_excel.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902676d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_sample = df_excel[:100]\n",
    "df_excel_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c51771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel.index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c917699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel_sample.index.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4cc8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel.columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62930a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_excel = df_excel.dtypes.reset_index()\n",
    "dtypes_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the column names that have a data type of object\n",
    "list(dtypes_excel[dtypes_excel[0] == 'object']['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel.Fare.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21835b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the range for each of the numeric variables.\n",
    "print('{:<20}|{:>7}'.format('Variable', 'Range'))\n",
    "print('__________________________\\n')\n",
    "for col in df_excel.columns:\n",
    "    if df_excel[col].dtype != 'O':\n",
    "        col_series = df_excel[col]\n",
    "        #print(f'Range of values in {col} is {col_series.max() - col_series.min()}')\n",
    "        print('{:<20}|{:>7}'.format(col, round(col_series.max() - col_series.min(), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ce4a41",
   "metadata": {},
   "source": [
    "Make a new python module, `acquire.py` to hold the following data aquisition functions:\n",
    "\n",
    "7. Make a function named `get_titanic_data` that returns the titanic data from the codeup data science database as a pandas data frame. Obtain your data from the _Codeup Data Science Database_. \n",
    "\n",
    "\n",
    "8. Make a function named `get_iris_data` that returns the data from the `iris_db` on the codeup data science database as a pandas data frame. The returned data frame should include the actual name of the species in addition to the `species_id`s. Obtain your data from the _Codeup Data Science Database_. \n",
    "\n",
    "9. Make a function named `get_telco_data` that returns the data from the `telco_churn` database in SQL. In your SQL, be sure to join all 4 tables together, so that the resulting dataframe contains all the contract, payment, and internet service options. Obtain your data from the _Codeup Data Science Database_. \n",
    "\n",
    "10. Once you've got your `get_titanic_data`, `get_iris_data`, and `get_telco_data` functions written, now it's time to add caching to them. To do this, edit the beginning of the function to check for the local filename of `telco.csv`, `titanic.csv`, or `iris.csv`. If they exist, use the .csv file. If the file doesn't exist, then produce the SQL and pandas necessary to create a dataframe, then write the dataframe to a .csv file with the appropriate name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a41d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire as ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe93518",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = ac.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f17243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = ac.get_iris_data()\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ef29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco = ac.get_telco_data()\n",
    "telco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a66139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
